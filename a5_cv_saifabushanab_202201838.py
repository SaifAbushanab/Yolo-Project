# -*- coding: utf-8 -*-
"""A5_CV_SaifAbushanab_202201838.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jWA6lswixh5EBZ1ikGg476Y69tdJQvm-
"""

! pip install ultralytics

!pip install ultralytics opencv-python

import matplotlib.pyplot as plt
import matplotlib.patches as patches
import cv2
import numpy as np
from PIL import Image
import requests
from io import BytesIO
import cv2
import torch
import time
from ultralytics import YOLO

!apt-get install ffmpeg

"""# YOLO_v10"""

video_path = "/content/test1.mp4"
model_path = "/content/yolov10n.pt"

model = YOLO(model_path)

# Measure inference time
start_time = time.time()

# Run tracking
results = model.track(source=video_path, save=True)

end_time = time.time()

# Calculate FPS
video_fps = 30  # known from earlier
duration = end_time - start_time
print(f"Inference Time: {duration:.2f} seconds")
print(f"Estimated FPS: {video_fps * (1 / duration):.2f}")

import os
from base64 import b64encode
from IPython.display import HTML


raw_path = "/content/runs/detect/track/test1.avi"
compressed_path = "/content/compressed_output_v10.mp4"

# Compress using ffmpeg
os.system(f"ffmpeg -i {raw_path} -vcodec libx264 -crf 23 {compressed_path}")

mp4 = open(compressed_path, 'rb').read()
data_url = "data:video/mp4;base64," + b64encode(mp4).decode()

HTML(f"""
<video width=400 controls>
  <source src="{data_url}" type="video/mp4">
</video>
""")

# v10
# Inference Time: 64.09 seconds
# Estimated FPS: 0.47

"""# YOLO_v11"""

video_path = "/content/test1.mp4"
model_path = "/content/yolo11n.pt"

model = YOLO(model_path)

# Measure inference time
start_time = time.time()

# Run tracking
results = model.track(source=video_path, save=True)

end_time = time.time()

# Calculate FPS
video_fps = 30  # known from earlier
duration = end_time - start_time
print(f"Inference Time: {duration:.2f} seconds")
print(f"Estimated FPS: {video_fps * (1 / duration):.2f}")

import os
from base64 import b64encode
from IPython.display import HTML


raw_path = "/content/runs/detect/track2/test1.avi"
compressed_path = "/content/compressed_output_v11.mp4"

# Compress using ffmpeg
os.system(f"ffmpeg -i {raw_path} -vcodec libx264 -crf 23 {compressed_path}")

mp4 = open(compressed_path, 'rb').read()
data_url = "data:video/mp4;base64," + b64encode(mp4).decode()

HTML(f"""
<video width=400 controls>
  <source src="{data_url}" type="video/mp4">
</video>
""")

# v11
# Inference Time: 58.72 seconds
# Estimated FPS: 0.51

"""# YOLO_v12"""

video_path = "/content/test1.mp4"
model_path = "/content/yolo12n.pt"

model = YOLO(model_path)

# Measure inference time
start_time = time.time()

# Run tracking
results = model.track(source=video_path, save=True)

end_time = time.time()

# Calculate FPS
video_fps = 30  # known from earlier
duration = end_time - start_time
print(f"Inference Time: {duration:.2f} seconds")
print(f"Estimated FPS: {video_fps * (1 / duration):.2f}")

import os
from base64 import b64encode
from IPython.display import HTML


raw_path = "/content/runs/detect/track3/test1.avi"
compressed_path = "/content/compressed_output_v12.mp4"

# Compress using ffmpeg
os.system(f"ffmpeg -i {raw_path} -vcodec libx264 -crf 23 {compressed_path}")

mp4 = open(compressed_path, 'rb').read()
data_url = "data:video/mp4;base64," + b64encode(mp4).decode()

HTML(f"""
<video width=400 controls>
  <source src="{data_url}" type="video/mp4">
</video>
""")

# v12
# Inference Time: 63.85 seconds
# Estimated FPS: 0.47

# Interpretation


# YOLOv11n achieved the fastest inference time at 58.72 seconds, and the highest FPS at 0.51. This indicates it can process video frames more quickly and is the most efficient among the three.
# YOLOv12n took 63.85 seconds with an FPS of 0.47, showing slower frame processing compared to v11.
# YOLOv10n recorded the longest inference time, 64.09 seconds, and also had an FPS of 0.47, matching YOLOv12n in speed but being slightly slower overall.

# Observation

# The difference in FPS between the models is small, but meaningful. YOLOv11n has about a 9% speed advantage over the other two.
# The processing speed of v12 and v10 are almost identical, both slightly lagging behind v11n.
# These variations are likely due to architectural differences: YOLOv11n appears to be better optimized for speed, while YOLOv12n may have additional complexity aimed at improving accuracy (though not shown here).
# All models perform below 1 FPS, suggesting this setup is more suitable for offline analysis rather than real-time applications.

# Conclusion

# From the results, it is clear that YOLOv11n provides the best trade-off between inference speed and performance, making it the most suitable model for time-sensitive video processing tasks in this test scenario.
# If real-time tracking or faster throughput is important, YOLOv11n should be the preferred choice.
# While YOLOv12n and YOLOv10n show comparable results, their longer processing times make them less optimal under the same conditions.